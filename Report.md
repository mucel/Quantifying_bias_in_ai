# Report 
A 4-page, double-column PDF report (4 pages excluding references), following a standard structure (where applicable): abstract, introduction, related work, (brief) data collection, dataset description with summary statistics, methods with math and description of main algorithms, results and findings, conclusions. This report will be evaluated according to how clearly and succinctly it is written, if the style is appropriate (e.g., figures with captions), if it contains all relevant contents, and how solid the results are.

## Abstract 
...

## Introduction

As LLMs are becoming more increasingly used in everyday life. There has arisen a need to detect and mitigate biases. There are various methods in how to approach this including creating new scores and data sets to gain better insight. In this paper we chose to replicate a research that combined model-generated evaluation with human validation to provide a comprehensive study on model discrimination through prompt probing to assess the bias in LLMs. 


The hottest topic at the moment has been analysing ChatGPT, which was the first to come out and the fastest company to gain a million users in a day. However, this company keeps growing both in users and its products. Just a few days ago OpenAI launched their newest model of ChatGPT that includes more languages as the company strives for accessibility. 


##  Background and Experimental Setup
...

## Method
...

## Prompt Biases 
...

## Discussion 
...

## Conclusion 
...



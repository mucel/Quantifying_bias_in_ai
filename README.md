# Quantifying bias in AI 
By Māra Učelniece, Michalina Loch, Ralfs Brutāns. 


##### Abstract

Large Language Models are known for perpetuating if not amplifying the biases of society, but often the issues with analysing them are do to the lack of universalizability of the methods. This research will address the biases that accur in one of the most popular at LLM at the moment - ChatGPT to asses the differences in steryotypical bias between language. The language that will be analnyzed is latvian, as there is little reserach regarding this and as two people out of this research are Latvians. The method we want to use is mainly promt probing. This method was chosen based on a literature review regarding various approaches. 

We would analyse ChatGPT-4o with promts to analyse steriotypical implicit biases. This paper was chosen for replication based on the availability in data of the exact promts that were used to investigate biases. 

Possibly cross validation between the prompts to analayse the 
differences. 

##### Research questions 
A list of research questions you would like to address during the project.  

    To what extent [a specific language model / a variety of popular models] show a difference in bias when encountering prompts in different languages?

##### Dataset
List the dataset(s) you want to use, and some ideas on how do you expect to get, manage, process and enrich it/them. Show you've read the docs and are familiar with some examples, and you've a clear idea on what to expect. Discuss data size and format if relevant.

    Large Language Models:  
        ChatGPT (OpenAI)
        Possibly open-source models:  Gemini (Google)  BLOOM(BigScience)  LLaMA2(Meta)   

* Reinforcement Learning regarding the mitigation of biases is quite interesting in training LLM’s. As it does not mitigate the biases, but only helps the user not gain unwanted answers. 

##### A tentative list of milestones for the project
Add here a sketch of your planning for the coming weeks. Please mention who does what.

    Explore current research + possible data sets (all) 
    -> Decide on a statistical method + data set (all)
    -> Translate to latvian. 
    -> Do the model prompting. 
    -> Gaining our metric of bias in data by using the benchmark method 
    -> Work on the report 
    -> Documenting the steps along the way (all)
    -> Evaluation of obtained bias
    -> Explanation/ summarizing the impact of bias in a report 
    -> Relation to our (main) research question(s)

##### Documentation
This can be added as the project unfolds. You should describe, in particular, what your repo contains and how to reproduce your results.

At the moment our repo only contains our chosen license and the readme file, the literature review files, report, and the sheet for prompts. We are working on translating the prompts and working on the report with still ongoing research being made. 


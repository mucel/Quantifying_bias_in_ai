# Quantifying bias in AI 
By Māra Učelniece, Michalina Loch, Ralfs Brurāns. 


##### Abstract

"The new regulatory framework proposal on Artificial Intelligence (AI) published by the European Commission establishes a new risk-based legal approach." (De Alcala et al.). This risk assessment will be addressing bias and the ways to evaluate and possibly mitigate them. In this work we apply statistical approaches to a .... data set, which is based on automatic decision making. 

The method we want to use ...

This method was chosen based on ... 

##### Research questions 
A list of research questions you would like to address during the project.  

    1. What is the best statistical method to quantify bias? 
    2. How does the model used for creating the algorithm influence bias? 
    3. Is it enough to only quantify bias afterwards? 
    4. ... 

##### Dataset
List the dataset(s) you want to use, and some ideas on how do you expect to get, manage, process and enrich it/them. Show you've read the docs and are familiar with some examples, and you've a clear idea on what to expect. Discuss data size and format if relevant.

    Large Language Models:  
        BERT or ChatGPT 


##### A tentative list of milestones for the project
Add here a sketch of your planning for the coming weeks. Please mention who does what.

    Explore current research + possible data sets (all) 
    -> Decide on a statistical method + data set (all)
    -> .... 
    -> Gaining our metric of bias in data 
    -> Documenting the steps along the way (all)
    -> Evaluation of obtained bias
    -> Explanation/ summarizing the impact of bias in a report 
    -> Relation to our (main) research question(s)

##### Documentation
This can be added as the project unfolds. You should describe, in particular, what your repo contains and how to reproduce your results.

At the moment our repo only contains our chosen license and the readme file. 

